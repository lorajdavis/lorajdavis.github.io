<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Davis - ArchivesSpace Member Meeting Presentation</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
						<h1>WHEN YOUR METADATA IS MESSYDATA:</h1>
						<h2>Subject Cleanup via the ArchivesSpace API</h2>
						<br />
						<br />
						<p>Lora J. Davis | Digital Archivist | Johns Hopkins University</p>
				</section>
				<section>
					<section>
						<h3>ArchivesSpace Migration as an Opportunity</h3>
					</section>
					<section>
							<h3>Needs</h3>

							<ul>
								<li>Have subject terms in ArchivesSpace</li>
								<li>Subject terms that are:
									<ul>
										<li>consistent (e.g. minimize duplication)</li>
										<li>controlled (e.g. from an appropriate authority file)</li>
									</ul>
								</li>
							</ul>
					</section>
					<section>
						<h3>Wants</h3>

							<ul>
								<li>Make our data "linked data ready"</li>
								<li>Convert existing LCSH terms to FAST headings</li>
								<li>Get experience using the ArchivesSpace API</li>
							</ul>

							<aside class="notes" data-markdown>
								- Looking toward a future where our archival description lives in the same index as our Institutional Repository and MARC catalog records.
								- Subjects as a way to colocate records from various sources.
								- Switched to FAST because FAST is optimised for Linked Data. Headings have identifiers, unlike LCSH.
								- Yea, may be loss of detail in converting to FAST, but we cared more about being Linked Data ready than preserving granularity.
							</aside>
					</section>
				</section>
				<section>
						<h3>Step 1: Migrate</h3>

						<img src="img/migrator.png" />

						<aside class="notes" data-markdown>
							* ArchivesSpace 1.4.2 with container management plugin.
							* Ran barcoder.
							* Migrated WITHOUT subjects.
						</aside>
				</section>
				<section>
					<section>
							<h3>Step 2: Convert LCSH Subjects to FAST</h3>

							<img src="img/namefail.PNG" />

							<aside class="notes" data-markdown>
								* Exported existing subject terms from AT tables.
								* Used OpenRefine to run the list of existing LCSH headings against OCLC's FAST API to convert headings to FAST.  Also created some new headings (result of compound headings being broken apart).
								* Had a cataloger review this work (about a week to review 508 terms; guesstimate of 60-70% accuracy with OpenRefine process).
							</aside>
					</section>
					<section>
							<h3>Step 2: Convert LCSH Subjects to FAST (cont.)</h3>

							<img src="img/json.PNG" /> <img src="img/subject.PNG" />

							<aside class="notes" data-markdown>
								* Added FAST IDs into Authority ID field.
								* Questions about this process should be directed to Eric.
							</aside>
					</section>
				</section>
				<section>
						<h3>Step 3: Generate JSON and POST</h3>

						<pre><code data-trim>
import json
import requests

baseURL = 'http://YOURBACKENDURL:8089'
user='YOURUSERNAME'
password='YOURPASSWORD'

auth = requests.post(baseURL + '/users/'+user+'/login?password='+password).json()
session = auth["session"]
headers = {'X-ArchivesSpace-Session':session, 'Content_Type':'application/json'}

with open('YOURJSONFILE.json') as jsonfile:
	for line in jsonfile:
		json_obj = json.loads(line)
		json_string = json.dumps(json_obj)
		subjects = requests.post(baseURL+'/subjects', headers=headers, data=json_string).json()
		print subjects
						</code></pre>

						<aside class="notes" data-markdown>
							* Follow JSON model
							* One line per subject record
							* Warning about special characters, character encoding issues, and byte order marks
						</aside>
				</section>
				<section>
						<h2>All Done!!!</h2>

						<ul>
							<li>Uh, nope</li>
							<li>We've got:
								<ul>
									<li>Subject records</li>
									<li>Accession records</li>
									<li>Resource records</li>
								</ul>
							</li>
							<li>But we don't got:
								<ul>
									<li>Subject records that are *linked* to accession and resource records</li>
								</ul>
							</li>
						</ul>
				</section>
				<section>
					<section>
							<h3>Step 4: GET <em>all</em> Subjects, Resources, and Accessions via API</h3>

<pre><code>
import json
import requests

baseURL = 'http://YOURBACKEND:8089'
user='USERNAME'
password='PASSWORD'

auth = requests.post(baseURL + '/users/'+user+'/login?password='+password).json()
session = auth["session"]
headers = {'X-ArchivesSpace-Session':session, 'Content_Type':'application/json'}

endpoint = '/repositories/3/accessions'
arguments = '?page=1&page_size=3000'

output = requests.get(baseURL + endpoint + arguments, headers=headers).json()
print(json.dumps(output.get('results'), indent=2))
</pre></code>

							<aside class="notes" data-markdown>
								* Python script to GET all subjects, including:
								  * Subjects that were already in (AAT genre forms, local terms, university functions, etc.)
									* FAST subjects we've just created
								* Python script to GET resources and accessions while we're at it
							</aside>
					</section>
					<section>
						<h3>Step 4 (aside): Client Option</h3>

						<img src="img/client.PNG" />

						<aside class="notes" data-markdown>
							* Client intially seemed like the way to go, but when we started yanking all our accessions and resources we started encountering timeout issues.
							* Using GET script showed a significant amount of time savings.
							* Script also allowed us to do some initial parsing of the data (e.g. removing the pagination header that came out with the JSON).
						</aside>
					</section>
				</section>
				<section>
					<section>
							<h3>Step 5: Link Subjects to Resources/Accessions</h3>

							<img src="img/fiddle.png" />

							<aside class="notes" data-markdown>
								* Had preserved the subject links to resources and accessions in AT.
								* Exported relevant AT tables into an Access Database.
								* Created a table in Access that mapped extern IDs from AT to new ASpace URIs.
								* Used Access to export JSON (templating with reports) that relinked subjects to accessions/resources.
								* Merged new JSON files with dump of accessions and resources using JSFiddle.
							</aside>
					</section>
					<section>
							<h3>Step 5 (aside): Our Unique Situation</h3>

							<ul>
								<li>We were doing this at the time of initial migration, so this workflow made sense for our use case.</li>
								<li>This might also work well if you're getting subjects from MARC records or a homegrown database.</li>
								<li>Essentially, your mileage may vary.</li>
							</ul>
					</section>
				</section>
				<section>
						<h3>Step 6: Generate JSON and POST</h3>

<pre><code>
import json
import requests

baseURL = 'http://YOURBACKENDURL:8089'
user='YOURUSERNAME'
password='YOURPASSWORD'

auth = requests.post(baseURL + '/users/'+user+'/login?password='+password).json()
session = auth["session"]
headers = {'X-ArchivesSpace-Session':session, 'Content_Type':'application/json'}

with open('YOURJSONFILE.json') as jsonfile:
	for line in jsonfile:
		json_obj = json.loads(line)
		uri_print = json_obj['uri']
		json_string = json.dumps(json_obj)
		pushit = requests.post(baseURL + uri_print, headers=headers, data=json_string).json()
		print pushit
</code></pre>

						<aside class="notes" data-markdown>
						* Follow JSON model for Resources and Accessions
						* One line per Resource/Accession record
						* Warning: We thought we'd be "smart" and lump resources and accessions together - don't do this.  Happy to explain in greater detail why, but essentially there's versioning issues that must be kept in mind.
					</aside>
				</section>
				<section>
						<h3>Additional Resources</h3>

						<ul>
							<li>"The Triad"
								<ul>
									<li>Valerie Addonizio, Archivist, vaddoniz@jhu.edu</li>
									<li>Lora Davis, Digital Archivist, ljdavis@jhu.edu or @lorajdavis</li>
									<li>Eric Hanson, Digital Content Metadata Specialist, ehanson8@jhu.edu</li>
								</ul>
							<li>GitHub
								<ul>
									<li>JHU: https://github.com/jhu-archives-and-manuscripts</li>
									<li>Personal: https://github.com/lorajdavis/</li>
								</ul>
							</li>
							<li>THANK YOU FOR SHARING!!!</li>
						</ul>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
